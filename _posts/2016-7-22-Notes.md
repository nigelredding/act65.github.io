---
layout: post
title: Novelty
---

# Abstract

blah blah

### Outline

* What is novelty detection? What is the setting?
    * How does this relate to unsupervised learning and what does this mean?
    * How does deep learning come into it?
* How do we want to use it? What is our setting?
* Methods to solve;
    * Certainty
    * GANs
    * Context
    * Attention
* Discussion

# Novelty

Background on novelty detection.

## Define: Novelty, anomalies and outliers

Let's firm up some definitions. What do we mean by a novelty, an anomaly and an outlier? and what is the difference?

Novelty implies the 'newness' of an observation. That in our interactions with some environment, we have yet to observe some event, and when we finally do, it is considered novel. (So can the same event be novel twice?)

Anomaly is an observation that is 'different' to what was expected. The key to this one is context. An (a priori) unusual event may be likely given the context (e.g. ...?). 

An outlier is an observation that is 'far away' from the rest of our observations, given some distance measure. So in our case we would interpret this as being unlikely given the prior distribution (???). How does this one relate to context?

So these seem to be measures of distance and difference between our observations. What measure is the correct one for our setting? Why not learn the measure, rather than trying to hand craft it.


### Types of anomaly

Anomalies come in three types. Source - [iwringer's blog](https://iwringer.wordpress.com/2015/11/17/anomaly-detection-concepts-and-techniques/)

<i>
> * Contextual Anomalies, If a data instance is anomalous in a specific context, but not otherwise ( anomaly if occur at certain time or certain region. e.g. large spike at middle of night)
* Collective Anomalies. If a collection of related data instances is anomalous with respect to the entire data set, but not individual values. They have two variations.
    * Events in unexpected order ( ordered. e.g. breaking rhythm in ECG)
    * Unexpected value combinations ( unordered. e.g. buying large number of expensive items)</i>

I would like to add a further distinction; is the datapoint fundamentally different or just a novel combination of existing (known) things?

> "Your best-friend and your wife are sleeping together."

> ""


None of the words in the sentence (Best-friend, wife, sleeping, ...) are themselves anomalous, what makes the sentence worth paying attention to is that it defies expectations. It is an unusual and unexpected composition of known words. However, in ... ??? 

Relates to https://en.wikipedia.org/wiki/Symbol_grounding_problem ??

##### Levels of anomaly

Elephant... Picture?!?


## The problem

Supervised novelty detection isnt paticularly interesting. In the sense that we have some ... then its just two class classification. And its not novelty that we are detection, rather previously novel things, which isn't the same.

##### Two class classification

Is this observation novel or not?

##### Setting

The domain. Large number of negative examples, few positive examples -> anomaly detection [Andrew Ng's ML course on Coursera](https://www.coursera.org/learn/machine-learning/)

> ... often there are very different types of anomalies. There are so many things that could go wrong that could the aircraft engine. And so if that's the case, and if you have a pretty small set of positive examples, then it can be hard for an algorithm to learn from your small set of positive examples. And in particular, you know future anomalies may look nothing like the ones you've seen so far. [paraphrased from Andrew Ng's ML course on Coursera](https://www.coursera.org/learn/machine-learning/)

In general the anomalies you have seen are unlikely to share common features (??) which mean there is no pattern we can extract from them to help classify them ... ?? other than that they are different from the non-anomalous observations.

##### Supervised?

Does it even make sense to do supervised novelty detection? Can a novelty can be novel more than once... if we are to train on/learn from a novelty then we are saying that we expect novel things in the future to be similar to the novel things we have seen before, but this is a contradiction. The whole point of novelty is that we haven't seen it before...

##### Noisy labels and false positives

How much can we really trust an observation that has been labelled anomalous, and vice versa? Since we have soo many negative examples, what happens if we train on a few anomalous examples? Given such a large size difference in the datasets (positive and negative examples of novelty) it is likely there are many novel observations in the negative dataset.

Let’s consider there are 1000 patients and 10 of them have breast cancer. There is a test ( a model) that detect cancer, which will capture 90% of patients who has cancer (true positives). However, it says yes for 10% of healthy patients ( false positives).

|        | Healthy        | Not healthy  |
| ------------- |:-------------:| -----:|
| Predicted healthy     |  |  |
| Predicted not healthy      |  |   |

The problem being that we start calling anything a novelty.

##### Inverse trend spotting

is this just the opposite of spotting trends? and therefore the same underlying problem?

### Formulations

##### Bayesian

Let A,B be two sources from $\mathcal{A}$, the source of all things we expect, and $\mathcal{B}$, the source of things we didnt expect (aka novel and anomlaous events).


$$X = \frac{P(A\mid D,v)}{P(B\mid D,v)} = \frac{P(v\mid D,A)}{P(v\mid B)}\frac{P(A)}{P(B)}$$

So if $P(A\mid D,v) = P(B\mid D,v)$ then $X = 1$. .. ??

* What is $P(v\mid B)$?? and how can we ever get a goot/accurate estimate for it?
* How can we objectivelty choose $P(B)$ or $P(A)$... as $P(A) = 1-P(B)$?

##### Algorithmic information theory



##### Game theory

A minimax game between 

##### Clustering/density


##### Prediction error


##### ???

* Dynamical systems
* ??
* Manifold learning? and distances? 
* 

### Other interesting questions

* How different should stimulus be?
* How often must a stimulus be seen before it stops being novel?
* 

## Motivation

Why is novelty detection important? What type of novelty detection are we interested in?

Applications?

* Active learning
* Directing attention
* Efficiency
* 

* Real world examples?





## The (general) solution
```python
while detecting:
    x = get_next_datapoint()
    
    #use a profile of what is normal to detect anomalies
    if is_different(normal,x);
        novelties.add(x)
        
    #build a profile of the normal behavoiur
    normal.update(x)

```
[Data Mining Anomaly Detection](https://www-users.cs.umn.edu/~kumar/dmbook/dmslides/chap10_anomaly_detection.pdf)




## Existing techniques

How do these existing techniques fit into the general solution?

<i>
> Several anomaly detection techniques have been proposed in literature. Some of the popular techniques are:
* Density-based techniques (k-nearest neighbor,[6][7][8] local outlier factor,[9] and many more variations of this concept[10]).
* Distance based
* Subspace-[11] and correlation-based[12] outlier detection for high-dimensional data.[13]
* One class support vector machines.[14]
* Replicator neural networks.[15]
* Cluster analysis-based outlier detection.[16][17]
* Deviations from association rules and frequent itemsets.
* Fuzzy logic based outlier detection.
* Ensemble techniques, using feature bagging,[18][19] score normalization[20][21] and different sources of diversity.[22][23] 
* Convex Hull Method
* Grubbs test
* Base rate fallacy, ROC
* Likelihood
* Hand design features [Andrew Ng...]
[Wikipedia](https://en.wikipedia.org/wiki/Anomaly_detection)
</i>

### Open source projects

https://github.com/twitter/AnomalyDetection
https://github.com/numenta/NAB
https://github.com/etsy/skyline

### Companies

* http://info.prelert.com/
* https://anomaly.io/

Anomaly Detection is mostly done with custom code and proprietary solutions.  [iwringer's blog](https://iwringer.wordpress.com/2015/11/17/anomaly-detection-concepts-and-techniques/) 

### Literature

http://arxiv.org/pdf/0710.3742v1.pdf




### Short commings
Why dont these work in practice? Show a couple of examples? or should i be adressing each of the examples individually?

##### Statistical approahces
> Limitations of Statistical Approaches
* Most of the tests are for a single attribute
* In many cases, data distribution may not be
known
* For high dimensional data, it may be difficult to
estimate the true distribution [Data Mining Anomaly Detection](https://www-users.cs.umn.edu/~kumar/dmbook/dmslides/chap10_anomaly_detection.pdf)

##### Metric based approaches




## Evaluation
How will we know if our algorithm can detect novelties? How should evaluation differ between detecting novelty and anomalies (which types?)?


Requires supervised learning... Dont know if I like this.

Other ways? Novelties shouldnt be frequent -> design some threshold...? Some prior on how likely we think novelty is. Nah, this sounds crap.

### Metrics



### Benchmark datasets

* http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html
* https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)
* https://github.com/numenta/NAB
* https://research.yahoo.com/news/announcing-benchmark-dataset-time-series-anomaly-detection

[iwringer's blog](https://iwringer.wordpress.com/2015/11/17/anomaly-detection-concepts-and-techniques/) 

##### Suggested -> MNIST

Use mnist w/o fours. Why?!?
Is testing without training on fours even a good measure of novelty detection?



# Unsupervised learning

Fundamental goal of unsupervised learning is ??. How does that apply here?



### Online clustering

Imagine you are the front of house in a busy restaurant. Your job is to seat similar people together. So, when your first customer asks for a table (customers always come alone), it is an easy choice. You simply seat them at the nearest table. But, when the second customer arrives, you need to decide if this customer is more similar to the first customer or to some subset of your future customers.

The problem is that the distribution of 'types' of person changes with every new customer. So any solution ... If we relaxed the assumption that once a person is seated, they cannot move, then this allows you to adapt to the changing distribution.

However, no a different problem ... computational complexity.

#### Chinese restaurant process

> Imagine a restaurant with countably infinitely many tables, labelled $T_1, T_2, ..., T_k$. Customers walk in and sit down at some table. The tables are chosen according to the following random process.
1. The first customer always chooses the first table.
2. The nth customer chooses the first unoccupied table with probability $\frac{\alpha}{n-1+\alpha}$, and an occupied table with probability $\frac{c}{n−1+\alpha}$, where c is the number of people sitting at that table.

[Princeton COS 597C: Bayesian nonparametrics](https://www.cs.princeton.edu/courses/archive/fall07/cos597C/scribe/20070921.pdf)


??? But this has no notion of the similarity between customers??? 

Instead of seating people at different tables, this restaurant has decided that ...
features of people are grouped.

https://en.wikipedia.org/wiki/Chinese_restaurant_process

http://blog.datumbox.com/the-dirichlet-process-the-chinese-restaurant-process-and-other-representations/

Can you specify the variance of the number of tables for Chinese...

#### Indian buffet

http://mlg.eng.cam.ac.uk/zoubin/papers/ibptr.pdf


#### Dirichlet ... 
????

#### k-Means
$O(N^?)$ per timestep...

### Weak labels

[Clustering](https://arxiv.org/abs/1604.03628) to find labels and then training for features. (How much positive feedback? Does it diverge?)

### Semi - supervised 

?? what about this? 
or transfer learning?

# Astronomy (The setting)

* Infinite data.
* Cannot store, cannot review, cannot process more than once.
* Detect unusual ...? 
    * (what is the definition of unusual?)
    * we need some metric?
        * the probability that we see features x, y, and z together (joint probability) = P(x,y,z)
* Online learning.
* BIG data.
* Sequential images/video.

Goals. 
* Find;
    * exoplanets
    * ??? supernova, blackholes, ... why?
    * new stuff...
* Monitor ???
* STEI
* Test
    * relativity
    * ??? (poincares conjecture???)
* Novelty ?!? Do we mean changes or new things? (what is the difference?)

### other

Mean average precision, recall, ???

<img src="Images/Voorweep.jpg" height=200 width=200>



# Reconstruction error



# Certainty

The aim is to use an algorithms certainty of a solution as a metric for novelty detection. We expect that as the algorithm learns, it becomes more certain of more common phonomena/inputs. So when an unusual event is input, the algorithm doesnt know ...

We define certainty to be; the level consistency in a prediction, given pertubations to the system predicting. Ie, if given a similar (in what senes?) input then it would ... 
so a definition of cts?
Why should this be true?

## Entropy

See [here]() a quick investigation into the relationship between the entropy of a softmax layer and its predictions.

However, Lecun ... Training on noise... i need to do this, and read this paper?

Competitive features, sparsity?
Test/understand with optimising for max activation? (of autoencoders?)

Pic of mnist 
* heat map weights - single layer
* classification of noise

Problem with softmax. It is saying, the input must be one of these, ...

The problem is that these nets are poor scientists, only looking to fit patterns. They do not (generally) consider alternative, or null, hypotheses.How can we get these nets to falsify and test their claims?



## Stability

Effectively, our definition of certainty is a difinition of stability.

### Dropout 
Gaussian process Yarin Gal.
http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html

__TODO__ Heat map of reconstruction variance under dropout. 

### Additive noise

This leads to the question, why dropout? How else can we perturb the system to check for stability? We could;
* add noise to the inputs (a denoising autoencoder),
* 

### Conclusions

The interesting lesson to take away?!? Is that by training a network on inputs we are making 'normal' outputs become more stable.

## Other ??

Probabilistic backprop?
Variational auto-encoders?


# Context

## Definition

???

## How does this apply to novelty?

> "Imagine, for example, the sudden unvieling of a large doeful elephant elegantly smuggled onto the stage by a professional magician." []()

The elephant is both anomalous and not, depending on what level of perception you concider and what context you consider. The precence of the elephant, given the visual cues and context; big ears, a skinny tail, a long trunk, size of a small bus, grey wrinkly skin is not suprising (however, it might be if one of these were different, e.g. a shiny pink elephant). But at the higher level of perception and context, being; we are inside, don't see how the elephant could have got there, I would have seen it... it is very suprising.


### Problems with context

Where do we get it from? To form out initial hypotheses?

### Previous work

#### Word2vec

Proof of concept, skipgram, Noise-Contrastive Training

#### Recent work

Context can be use to get a supervisor signal to train a neural network. The general idea is similar to de-noising autoencoders. We remove some information and ask a net to predict the likely removed information, given what we didnt remove, its context. This paradigm has been very successful when applied to word embeddings, see [word2vec](). Recently (in the last year), others have been inspired by this idea and applied it to unsupervised learning with images.

<img src=“images/Images/Patches2.png">
[Unsupervised Visual Representation Learning by Context Prediction](http://arxiv.org/abs/1505.05192)
<img src="Images/Patches1.png">
[Unsupervised Visual Representation Learning by Context Prediction](http://arxiv.org/abs/1505.05192)

![pactches](https://github.com/act65/NoveltyDetection/blob/master/Images/Patches2.png)
<img src="Images/Jigsaw.png">
[Unsupervised Learning of Visual Representations by Solving Jigsaw Puzzles](http://arxiv.org/abs/1603.09246)
 
<img src="Images/ContextEncoder.png">
[Context Encoders: Feature Learning by Inpainting](https://arxiv.org/abs/1604.07379)

Initial idea, lets just assume we have a function that gives us a set of features for each image (See [this]() for a more detailed thought process/derivation of the idea). Then our goal is to find relationships between the features, for example... 

Similar to LDA/topic modelling using features like a bag of words.
Grammars? Using the structure, of locations, of features to ???




## Reconstruction from context

```python
while detecting:
    x = get_next_datapoint()
    
    #use a profile of what is normal to detect anomalies
    if is_different(normal,x);
        novelties.add(x)
        
    #build a profile of the normal behavoiur
    normal.update(x)

```

Context could be;
* what happened at a previous time step,
* what is occuring at different spatial locations,
* the features in a bag (like bag of words, for high level features?!?)
* 

... what is the general version of this? So context is??? things that are 'close' to our situation? which we can transfer knowledge???



## Bag of features

##### Semantic segmentation

It is my hope, that using a segmantation algorithm, we can find the good/interesting features for context prediction.

Algorithms that can give us a set of interesting objects from an image. Our segmenter function, S, gives us a collection of patches of interest, p, within the image. $S:image \rightarrow O: O = \{p_1, ..., p_n\}, p_i \in \mathbb{R}^{w,d,h} $

Can the overlap, disjoint, ...?

Examples
<img src="Images/Deepmask.png" alt="mask">


## Our version?!? patches

__TODO__ test our some simple versions?
does this actually correlate with novelty?!?

## Generative adversarial networks

Explicitly caputres the problem we want to solve. 

Two class classification. Novel and not novel.

## Attention model: Inverse DRAW

https://openai.com/requests-for-research/#inverse-draw


# Discussion

## Disentangled representations

Want to have low generalisation?!!? Our nets are too good at using what they have learned and applying it to new inputs?!?

### Distinct features (problem)

So the problem, as shown in the picture below is that one class could cover the entire input space - shown in gray - (it could also be that the union of classes covers the input space). This would mean than any input would be classified as a 0, unless it is a 1,2...9. Obviously, this would tell us very little about novel inputs.

The only requirement for the algorithm to learn to categorise the inputs is that is can separate them.
<img src="Images/topology.png">

<img src="Images/separable.png">
